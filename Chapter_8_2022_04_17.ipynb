{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_8_2022_04_17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4EcLanSIYINR0tsD9Gfh2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d6518e3484544348ed45f68281a1dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f503fea7b9f240f29c83e9d371dc2316",
              "IPY_MODEL_8664d9274cdc4bf5b56f4a472fe3e61e",
              "IPY_MODEL_66cb65c85fd0466c9c8317e79032f220"
            ],
            "layout": "IPY_MODEL_ff3db53c10e7404fb2582cc3fb656839"
          }
        },
        "f503fea7b9f240f29c83e9d371dc2316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc957a083e0f4bcdaf02006e8165b520",
            "placeholder": "​",
            "style": "IPY_MODEL_6905ee02ab4749d29423220c1bf1f80f",
            "value": "Downloading: 100%"
          }
        },
        "8664d9274cdc4bf5b56f4a472fe3e61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c692de1d804ebc8a9451b42ffc6651",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b70527cbedd4fcba049b595644ac45c",
            "value": 1000
          }
        },
        "66cb65c85fd0466c9c8317e79032f220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdd58044dc81449d9970ec91c8777f27",
            "placeholder": "​",
            "style": "IPY_MODEL_9ede5906933e4eaf914ac55926e1cf7e",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "ff3db53c10e7404fb2582cc3fb656839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc957a083e0f4bcdaf02006e8165b520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6905ee02ab4749d29423220c1bf1f80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40c692de1d804ebc8a9451b42ffc6651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b70527cbedd4fcba049b595644ac45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdd58044dc81449d9970ec91c8777f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ede5906933e4eaf914ac55926e1cf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030d92fc9e254dc9a431161bbba1d2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_411dfef914c24d94892bb6960a857d6f",
              "IPY_MODEL_cd69fd0209a040b882a990c0a17bca56",
              "IPY_MODEL_4f977b0e9ee44b0b803f29a6da796c5d"
            ],
            "layout": "IPY_MODEL_6d28c75bd27a478f8d6079fac3ed1b59"
          }
        },
        "411dfef914c24d94892bb6960a857d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d321f3c9404641cab0a6b422cf8c5380",
            "placeholder": "​",
            "style": "IPY_MODEL_e9154909a2644f3ea437371317a3f5ef",
            "value": "Downloading: 100%"
          }
        },
        "cd69fd0209a040b882a990c0a17bca56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510e0a969c3a46b4b2962778c0fd31c3",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8b94874400249c7a0a11d3c4cdbc2cd",
            "value": 513302779
          }
        },
        "4f977b0e9ee44b0b803f29a6da796c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6547ced2e5b424489f66165bebe519b",
            "placeholder": "​",
            "style": "IPY_MODEL_635495da61974dbbb840a9bbc0d96755",
            "value": " 513M/513M [00:11&lt;00:00, 46.4MB/s]"
          }
        },
        "6d28c75bd27a478f8d6079fac3ed1b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d321f3c9404641cab0a6b422cf8c5380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9154909a2644f3ea437371317a3f5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "510e0a969c3a46b4b2962778c0fd31c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b94874400249c7a0a11d3c4cdbc2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6547ced2e5b424489f66165bebe519b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "635495da61974dbbb840a9bbc0d96755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95a59c32b5df4ba093b1609d938b8d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e15549ace43f4c3aae05ff6ce3819099",
              "IPY_MODEL_ceeea9bb6b2348f7bbc38a00c67925fa",
              "IPY_MODEL_18cb3c628b9e425685929a01b9cca787"
            ],
            "layout": "IPY_MODEL_098fe947881249baad3757c348ad2b2d"
          }
        },
        "e15549ace43f4c3aae05ff6ce3819099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee75eec0ece94f058c440e7238348e50",
            "placeholder": "​",
            "style": "IPY_MODEL_49b6715d342047c6b7dbc7bb9fa265f1",
            "value": "Downloading: 100%"
          }
        },
        "ceeea9bb6b2348f7bbc38a00c67925fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526ec31ddd0740bb958014bd2eeb8516",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43befcb98b5c42ab8a9242e8267351c0",
            "value": 2825034
          }
        },
        "18cb3c628b9e425685929a01b9cca787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3c1954da084a4c908031cb42be362a",
            "placeholder": "​",
            "style": "IPY_MODEL_7c0bb849738c47599a796044ad747f7a",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "098fe947881249baad3757c348ad2b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee75eec0ece94f058c440e7238348e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b6715d342047c6b7dbc7bb9fa265f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "526ec31ddd0740bb958014bd2eeb8516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43befcb98b5c42ab8a9242e8267351c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a3c1954da084a4c908031cb42be362a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0bb849738c47599a796044ad747f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##- - 이전 코드 시작 - -"
      ],
      "metadata": {
        "id": "cojUtkL5NKiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratsnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cluXefIgNRdw",
        "outputId": "65490d33-7995-4dff-c8b2-6b691b0bedc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ratsnlp\n",
            "  Downloading ratsnlp-1.0.1-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 305 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4)\n",
            "Collecting flask-cors>=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111)\n",
            "Collecting pytorch-lightning==1.3.4\n",
            "  Downloading pytorch_lightning-1.3.4-py3-none-any.whl (806 kB)\n",
            "\u001b[K     |████████████████████████████████| 806 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting flask-ngrok>=0.0.25\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting Korpora>=0.2.0\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting transformers==4.10.0\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (1.21.5)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (4.64.0)\n",
            "Collecting fsspec[http]>=2021.4.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 43.4 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (2.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->ratsnlp) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (3.6.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0->ratsnlp) (2.23.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0->ratsnlp) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n",
            "Collecting dataclasses>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting xlrd>=1.2.0\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning==1.3.4->ratsnlp) (3.0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2021.10.8)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.37.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0->ratsnlp) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->ratsnlp) (3.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 37.6 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 676 kB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.4->ratsnlp) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.1.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=818f6949e1ce89beeaf0df27125325eb2d93931865eb01eb8ecb3591b4028b25\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, pyDeprecate, fsspec, aiohttp, xlrd, torchmetrics, tokenizers, sacremoses, huggingface-hub, future, dataclasses, transformers, pytorch-lightning, Korpora, flask-ngrok, flask-cors, ratsnlp\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed Korpora-0.2.0 PyYAML-5.4.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 frozenlist-1.3.0 fsspec-2022.3.0 future-0.18.2 huggingface-hub-0.5.1 multidict-6.0.2 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 ratsnlp-1.0.1 sacremoses-0.0.49 tokenizers-0.10.3 torchmetrics-0.8.0 transformers-4.10.0 xlrd-2.0.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#체크포인트 로드\n",
        "from transformers import GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        ")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d6518e3484544348ed45f68281a1dcb",
            "f503fea7b9f240f29c83e9d371dc2316",
            "8664d9274cdc4bf5b56f4a472fe3e61e",
            "66cb65c85fd0466c9c8317e79032f220",
            "ff3db53c10e7404fb2582cc3fb656839",
            "bc957a083e0f4bcdaf02006e8165b520",
            "6905ee02ab4749d29423220c1bf1f80f",
            "40c692de1d804ebc8a9451b42ffc6651",
            "8b70527cbedd4fcba049b595644ac45c",
            "fdd58044dc81449d9970ec91c8777f27",
            "9ede5906933e4eaf914ac55926e1cf7e",
            "030d92fc9e254dc9a431161bbba1d2a5",
            "411dfef914c24d94892bb6960a857d6f",
            "cd69fd0209a040b882a990c0a17bca56",
            "4f977b0e9ee44b0b803f29a6da796c5d",
            "6d28c75bd27a478f8d6079fac3ed1b59",
            "d321f3c9404641cab0a6b422cf8c5380",
            "e9154909a2644f3ea437371317a3f5ef",
            "510e0a969c3a46b4b2962778c0fd31c3",
            "b8b94874400249c7a0a11d3c4cdbc2cd",
            "d6547ced2e5b424489f66165bebe519b",
            "635495da61974dbbb840a9bbc0d96755"
          ]
        },
        "id": "Yh95qL-zNRgD",
        "outputId": "9067904c-981a-42f0-8c56-453d666b8ee3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d6518e3484544348ed45f68281a1dcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "030d92fc9e254dc9a431161bbba1d2a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토크나이저 로드\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    eos_token=\"</s>\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "95a59c32b5df4ba093b1609d938b8d89",
            "e15549ace43f4c3aae05ff6ce3819099",
            "ceeea9bb6b2348f7bbc38a00c67925fa",
            "18cb3c628b9e425685929a01b9cca787",
            "098fe947881249baad3757c348ad2b2d",
            "ee75eec0ece94f058c440e7238348e50",
            "49b6715d342047c6b7dbc7bb9fa265f1",
            "526ec31ddd0740bb958014bd2eeb8516",
            "43befcb98b5c42ab8a9242e8267351c0",
            "8a3c1954da084a4c908031cb42be362a",
            "7c0bb849738c47599a796044ad747f7a"
          ]
        },
        "id": "zFS0CPsWNRia",
        "outputId": "096a47fc-30b7-463a-f96b-45104c574024"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95a59c32b5df4ba093b1609d938b8d89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 입력값 만들기\n",
        "input_ids = tokenizer.encode(\"안녕하세요\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "Ig78X3-nNRki"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#그리드 서치\n",
        "import torch\n",
        "with torch.no_grad():\n",
        "  generated_ids = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=False,\n",
        "      min_length=10,\n",
        "      max_length=50,\n",
        "  )"
      ],
      "metadata": {
        "id": "JKmHIx8-NRpF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰 인덱스를 문장으로 복원하기\n",
        "print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bv3lM2ONe68",
        "outputId": "cb0c4a8c-ef8c-4345-f640-ea42cf752049"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#빔 서치\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        mix_length=10,\n",
        "        max_length=50,\n",
        "        num_beams=3,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCTcm0X0Ne9G",
        "outputId": "e09da1b8-ed96-4eaa-a990-d57c6b73ddb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그렇지 않습니다.\"\n",
            "\"그\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#반복 줄이기(1)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        no_repeat_ngram_size=3,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBpronO1Ne_i",
        "outputId": "9a4e5343-382c-4d6d-a477-79f001fe9339"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\" 하고 나는 물었다.\n",
            "\"그건 뭐죠?\" 나는 물었다.\n",
            "나는 대답하지 않았다.\n",
            "\"그런데 왜 그걸 물어요? 그건 무슨 뜻이에요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#반복 줄이기(2)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.0,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQVgVxbJNfBv",
        "outputId": "9f248e58-2d59-4a17-9782-97404ace419a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repetition_penalty=1.1\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.1,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebuCZ7CBNfDs",
        "outputId": "201117ab-4e49-4822-e299-843052c2d90d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"아니요, 저는요.\"\n",
            "\"그럼, 그건 무슨 말씀이신지요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repetition_penalty=1.2\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoEsmEnpNRrC",
        "outputId": "74389d77-6d01-43d2-a7ed-acb75d6d6008"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요, 아저씨. 저는 지금 이 순간에도 괜찮아요.\"\n",
            "\"그래서 오늘은 제가 할 수 있는 일이 무엇인지 말해 보겠습니다.\"\n",
            "\"이제\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repetition_penalty=1.5\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        repetition_penalty=1.5,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXuOz3hVNRtO",
        "outputId": "b02458c1-f5e5-484b-c4ae-5141446462f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요, 아저씨. 저는 지금 이 순간에도 괜찮아요. 그리고 제가 할 수 있는 일은 아무것도 없어요.\n",
            "이제 그만 돌아가고 싶어요.\n",
            "제가 하는 일이 무엇\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#탑-k 샘플링 1try\n",
        "with torch.no_grad():\n",
        "  generated_ids = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=True,\n",
        "      min_length=10,\n",
        "      max_length=50,\n",
        "      top_k=50,\n",
        "  )\n",
        "  print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBd-hgFZNSCm",
        "outputId": "fecf9d91-949a-464c-9bff-1cf5059765d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요’ 이벤트를 오는 2월19일까지 진행한다.\n",
            "이벤트 기간 중에는 ‘화이트댄스쇼’ ‘트램퍼싱’ 등 다양한 이벤트가 진행된다.</d> 인천시에 따르면 시는 지난달 말 인천시청에서 송\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YawDXyfONFI9",
        "outputId": "75c419f9-ce76-4a97-ce1c-5222073fb300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요’를 부르짖고 나섰다.\n",
            "‘한겨레’ 지면을 장식한 것은 그 자체로 뜨거운 ‘사랑의 열기’가 아닐 수 없다.\n",
            "지난 14일 최창식 목사는 ‘최진실 뉴스데스크’를 통해 “서울 시민들은\n"
          ]
        }
      ],
      "source": [
        "#탑-k 샘플링 2try\n",
        "with torch.no_grad():\n",
        "  generated_ids = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=True,\n",
        "      min_length=10,\n",
        "      max_length=50,\n",
        "      top_k=50,\n",
        "  )\n",
        "  print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##- - 이전 코드 끝 - -"
      ],
      "metadata": {
        "id": "v3H3368dNPvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 템퍼러처 스케일링\n"
      ],
      "metadata": {
        "id": "-sNtZhuzNx5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***템퍼러처 스케일링(temperature scaling)*** 이란 모델의 다음 토큰 확률 분포를 대소 관계의 역전 없이 분포의 모양만을 바꿔서 문장을 다양하게 생성하는 기법입니다.   \n",
        "다음 그림이 템퍼러처 스케일링을 적용한 예시입니다."
      ],
      "metadata": {
        "id": "tHx4iRqcOXjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><그림 - 템퍼러처 스케일링></center>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://i.imgur.com/2Lb8CGj.jpg\">\n"
      ],
      "metadata": {
        "id": "VRFL8EcFOXls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원래대로라면 `그` 다음 토큰 확률은 각각 `책`(0.5), `집`(0.4), `사람`(0.1)이었습니다.   \n",
        "템퍼러처 스케일링을 적용한 결과 그 확률이 `책`(0.75), `집`(0.23), `사람`(0.02)으로 바뀌었습니다. 마찬가지로 `그 책` 다음 토큰 확률도 각각 `이`(0.4), `을`(0.3), `읽`(0.3)에서 `이`(0.6), `을`(0.2), `읽`(0.2)으로 바뀌었습니다. 순위는 변하지 않았지만 원래 컸던 확률은 더 커지고, 작았던 확률은 더 작아져 확률 분포의 모양이 뾰족(sharp)해졌음을 알 수 있습니다."
      ],
      "metadata": {
        "id": "AELwJJf9OXta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "템퍼러처 스케일링은 모델의 출력 로짓(소프트맥스 변환 전 벡터)의 모든 요솟값을 `temperature`로 나누는 방식으로 적용합니다. 예를 들어 로짓이 [-1.0 2.0 3.0]이고 `temperature` 가 2라면 템퍼러처 스케일링 적용 후 로짓은 [-0.5 1.0 1.5]가 됩니다. 여기에 소프트맥스를 취해 다음 단어 확률 분포로 만듭니다. `temperature`가 1이면 전혀 변화가 생기지 않습니다. 음수라면 단어들 사이의 대소 관계가 완전히 뒤바뀌므로 0보다 큰 값을 지정해야 합니다."
      ],
      "metadata": {
        "id": "XtIOrIE9OXvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 코드는 탑-k 샘플링에 템퍼러처 스케일링을 적용한 코드입니다.  \n",
        "다음 단어를 선택할 때 확률값이 높은 50개에서 고르되, 그 확률값은 템퍼러처 스케일링(`temperature=0.01`)으로 바꾼다는 뜻입니다."
      ],
      "metadata": {
        "id": "kwueVqQ2OXxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#템퍼러처 스케일링\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        temperature=0.01,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UiETkYzQl1Z",
        "outputId": "cc81b817-53ba-4665-b8d7-c7f615f393ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드를 실행해 보니 탑-k 샘플링을 수행했음에도 그리디 서치로 생성한 문장과 같습니다."
      ],
      "metadata": {
        "id": "XmTGk9tFReA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 코드에서는 `temperature`를 0.01로 설정했는데, 이 값이 0에 가까울수록 확률 분포 모양이 원래보다 뾰족해집니다. 확률 분포 모양이 뾰족하다는 말은 원래 컸던 확률은 더 커지고 작았던 확률은 더 작아진다는 의미입니다. 그만큼 확률값 기준 1등 토큰이 다음 토큰으로 뽑힐 가능성이 커진다는 이야기입니다.   "
      ],
      "metadata": {
        "id": "5mxCqwuNOX0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`temperature`를 1보다 큰 값으로 설정한다면 확률 분포가 평평해집니다(uniform). 원래 컸던 확률과 작았던 확률 사이의 차이가 줄어든다는 이야기입니다.  \n",
        "바꿔 말하자면 확률값이 작아서(=모델이 다음 토큰으로 부적절하다고 예측) 기존 탑-k 샘플링에선 선택되기 어려웠던 토큰들이 다음 토큰으로 선택될 수 있습니다. 그만큼 다양한 문장이 생성될 가능성이 높아지지만 생성 문장의 품질이 나빠질 수 있습니다.  \n",
        "\n",
        "다음은 앞 코드에서 `temperature`값을 100000000.0으로 설정한 결과입니다."
      ],
      "metadata": {
        "id": "J1jPSrcPRkW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#템퍼러처 스케일링(100000000.0)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        temperature=100000000.0,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeDLO3FySRgg",
        "outputId": "f3f2fc4c-5a82-44bf-c45d-92e8b5c6ac2e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요라는 편지를 전해왔다.\n",
            "서운하기도 했다는 서씨가 이런 이야기를 하니 갑자기 화가 일어났다.\n",
            "그로부터 약 몇 달 전의 일이었다.\n",
            "여중 3반은 학생에게, 혹은 방생교육을 마치고서였대야만 한다고 그는 털어 버렸다.\n",
            "자네가 나를\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요약하자면 `temperature`를 1보다 작게하면 상대적으로 정확한 문장을, 1보다 크게 하면 상대적으로 다양한 문장을 생성할 수 있습니다. 템퍼러처 스케일링은 탑-k 샘플링, 탑-p 샘플링과 함께 적용해야 의미가 있습니다. 이어서 탑-p 샘플링 설명이 나옵니다."
      ],
      "metadata": {
        "id": "ypyO_UGkRkht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 탑-p 샘플링"
      ],
      "metadata": {
        "id": "96AiYxlnRkkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***탑-p 샘플링(top-p sampling)*** 은 확률값이 높은 순서대로 내림차순 정렬을 한 뒤 누적 확률값이 $p$ 이상인 최소 개수의 토큰 집합 가운데 하나를 다음 토큰으로 선택하는 기법입니다. ***뉴클리어스 샘플링(necleus sampling)*** 이라고도 부릅니다. 확률값을 기준으로 토큰을 내림차순 정렬해 그 값이 높은 토큰들을 다음 토큰 후보로 삼는다는 점에서는 탑-k 샘플링과 같지만, 상위 $k$개를 후보로 삼느냐(탑-k 샘플링), 누적 확률값이 $p$ 이상인 최소 개수의 토큰들을 후보로 삼느냐(탑-p 샘플링)에 따라 차이가 있습니다."
      ],
      "metadata": {
        "id": "4Zf7KfWZRkmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 그림은 `그`라는 컨텍스트를 입력했을 때 모델이 출력한 다음 토큰의 확률 분포입니다. $p$를 0.92로 설정했다고 가정해 봅시다. 가장 높은 확률을 가지는 토큰부터 시작해 누적 확률값이 $p$ 이상이 될 때까지 하나씩 순서대로 다음 토큰 후보에 추가합니다. 다음 그림에서 다음 단어 후보는 `책`부터 `회사`까지 9개, 그리고 이들의 누적 확률합은 0.94가 되는 것을 확인할 수 있습니다. $k$가 6인 탑-k 샘플링에서는 다음 단어 후보가 `책`부터 `의자`까지 6개, 그리고 이들의 누적 확률합은 0.68였던 것과 비교할 수 있습니다."
      ],
      "metadata": {
        "id": "a8K9WWeqRkob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><그림 - 탑-p 샘플링(1)></center>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://i.imgur.com/ZEQoJU2.jpg\">"
      ],
      "metadata": {
        "id": "E9KppsseRky9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 그림은 `그 사람`이라는 컨텍스트를 입력했을 때 모델이 출력한 다음 토큰 확률 분포입니다. $p$를 0.92로 설정했을 때 다음 토큰 후보는 `처럼`부터 `누구`까지 3개, 그리고 이들의 누적 확률합은 0.97인 것을 확인할 수 있습니다. $k$가 6인 탑-k 샘플링에서는 다음 토큰 후보가 `처럼`부터 `과`까지 6개, 그리고 이들의 누적 확률합은 0.99였던 것과 비교할 수 있습니다."
      ],
      "metadata": {
        "id": "0nRq_b3bUkqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><그림 - 탑-p 샘플링(2)></center>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://i.imgur.com/WjpElDc.jpg\">"
      ],
      "metadata": {
        "id": "IaFMMSXbUks6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "탑-p 샘플링은 누적 확률합으로 후보 토큰을 취하기 때문에 누적 확률합이 매 순간 비슷한 반면 후보 토큰 개수는 해당 분포에 따라 달라집니다. 반대로 탑-k 샘플링은 토큰 개수로 후보 토큰을 취하기 때문에 후보 토큰 개수는 일정한 반면 누적 확률합은 해당 분포에 따라 달라집니다.  \n",
        "다만 둘 모두 확률값이 낮은 토큰은 다음 토큰 후보에서 빠지므로 품질 높은 문장을 생성할 가능성을 높입니다."
      ],
      "metadata": {
        "id": "1RPUv77AUkzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 코드는 탑-p 샘플링을 수행합니다. 핵심 인자는 `do_sample=True`, `top_p=0.92`입니다.  \n",
        "샘플링 방식으로 다음 단어를 선택하되 $p$를 0.92로 설정한다는 뜻입니다. `top_p`에는 0~1 사이의 실수를 입력해야 합니다."
      ],
      "metadata": {
        "id": "6Qul2ToTRk1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#탑-p 샘플링(1)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_p=0.92,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B3LgmeuOXAS",
        "outputId": "8c909675-f8d0-4d3b-f91e-40cf3f2fbf0d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?' 라는 말이 나오면 \"아니 그냥 그냥 '~했습니다'라는 것이죠\"라고 대답합니다.\n",
            "하지만 그걸 두고 \"내가 저런 말을 못해서\"라는 이야기가 들리면 \"이거 내말이다\" 라고 대답합니다.\n",
            "물론 '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한편 `top_p`를 1.0으로 설정한다면 확률값이 낮은 단어를 전혀 배제하지 않고, 다음 단어 후보로 전체 어휘를 고려한다는 의미가 됩니다. `top_p`가 0에 가까울수록 후보 토큰이 줄어들어 확률값이 높은 토큰들만 남게 돼 그리디 서치와 비슷해집니다. \n"
      ],
      "metadata": {
        "id": "3pGKMuRnWxcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 앞 코드에서 `top_p`를 0.01로 설정한 결과입니다.   \n",
        "탑-p 샘플링을 수행했음에도 그리디 서치 결과와 같음을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "2DQ6GLvZXUDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#탑-p 샘플링(1) - 0.01\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        min_length=10,\n",
        "        max_length=50,\n",
        "        top_p=0.01,\n",
        "    )\n",
        "    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-KVS5AsXTpb",
        "outputId": "1ee13602-18b6-4d45-9ad6-034a763564aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\"그럼, 그건 뭐예요?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 종합 적용하기"
      ],
      "metadata": {
        "id": "ZJinaAO8XjoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 설명한 문장 생성 방식을 모두 종합해 적용해 봅시다.  \n",
        "그리디 서치나 빔 서치는 가장 높은 확률값을 내는 문장을 생성해주지만, 컨텍스트가 같을 때는 매번 같은 문장이 나오므로 샘플링 방식을 적용하겠습니다. 그리고 생성된 문장이 너무 짧거나 길지 않게 하고 반복되는 토큰을 될 수 있으면 배제하며 템퍼러처 스케일링으로 원래 확률 분포를 조금 뾰족하게 해 확률값이 높은 토큰이 더 잘 나오도록 하겠습니다.   \n"
      ],
      "metadata": {
        "id": "v9vGBE5MXlbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 탑-k 샘플링과 탑-p 샘플링을 동시에 적용해 확률값이 낮은 토큰들은 후보 단어에서 제외하겠습니다.  \n",
        "다음은 이러한 내용을 적용한 코드입니다."
      ],
      "metadata": {
        "id": "p6syopswYEuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#종합 적용\n",
        "with torch.no_grad():\n",
        "  generated_ids = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=True,\n",
        "      min_length=10,\n",
        "      max_length=50,\n",
        "      repetition_penalty=1.5,\n",
        "      no_repeat_ngram_size=3,\n",
        "      temperature=0.9,\n",
        "      top_k=50,\n",
        "      top_p=0.92,\n",
        "  )\n",
        "  print(tokenizer.decode([el.item() for el in generated_ids[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00gNyDnrXgCc",
        "outputId": "ad94a42c-331e-499b-eb90-a25f1c4eac85"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요?\"하고 물었다.\n",
            "그러자 유준은 \"아니요, 저는 그렇게 생각하지 않는다\"고 대답했다.\n",
            "이어 그는 잠시 말을 멈추고 웃더니 다시 입을 열었다.\n",
            "유준이 한 대 맞췄는데, 나는 그때도 난생처음 들은\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "역시 코드를 실행할 때마다 다른 문장이 생성됩니다."
      ],
      "metadata": {
        "id": "vEy_xX5WY23w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 맺음말\n",
        "---\n",
        "이번 절에서는 프리트레인을 마친 언어 모델을 가지고 문장을 생성하는 방법을 실습해 보았습니다.   \n",
        "다음 단어 후보들을 모두 탐색하는 것은 불가능에 가까우므로 그리디 서치, 빔 서치, 탑-k 샘플링, 탑-p 샘플링 등 기법이 제안되었습니다."
      ],
      "metadata": {
        "id": "cqnFks7CY4SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0rWm6h3YZPJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}